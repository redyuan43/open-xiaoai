import asyncio
import json
import re
import threading
import time

from xiaozhi.event import EventManager
from xiaozhi.ref import set_xiaozhi
from xiaozhi.services.audio.kws import KWS
from xiaozhi.services.audio.vad import VAD
from xiaozhi.services.protocols.typing import (
    AbortReason,
    DeviceState,
    EventType,
    ListeningMode,
)
from xiaozhi.services.protocols.websocket_protocol import WebsocketProtocol
from xiaozhi.utils.base import get_env
from xiaozhi.utils.config import ConfigManager
from xiaozhi.xiaoai import XiaoAI


class XiaoZhi:
    """æ™ºèƒ½éŸ³ç®±åº”ç”¨ç¨‹åºä¸»ç±»"""

    _instance = None

    @classmethod
    def instance(cls):
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            cls._instance = XiaoZhi()
        return cls._instance

    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨ç¨‹åº"""
        # ç¡®ä¿å•ä¾‹æ¨¡å¼
        if XiaoZhi._instance is not None:
            raise Exception("XiaoZhiæ˜¯å•ä¾‹ç±»ï¼Œè¯·ä½¿ç”¨instance()è·å–å®ä¾‹")
        XiaoZhi._instance = self

        # è·å–é…ç½®ç®¡ç†å™¨å®ä¾‹
        self.config = ConfigManager.instance()

        # çŠ¶æ€å˜é‡
        self.device_state = DeviceState.IDLE
        self.voice_detected = False
        self.current_text = ""
        self.current_emotion = "neutral"

        # éŸ³é¢‘å¤„ç†ç›¸å…³
        self.audio_codec = None

        # äº‹ä»¶å¾ªç¯å’Œçº¿ç¨‹
        self.loop = asyncio.new_event_loop()
        self.loop_thread = None
        self.running = False

        # ä»»åŠ¡é˜Ÿåˆ—å’Œé”
        self.main_tasks = []
        self.mutex = threading.Lock()

        # åè®®å®ä¾‹
        self.protocol = None

        # å›è°ƒå‡½æ•°
        self.on_state_changed_callbacks = []

        # åˆå§‹åŒ–äº‹ä»¶å¯¹è±¡
        self.events = {
            EventType.SCHEDULE_EVENT: threading.Event(),
            EventType.AUDIO_INPUT_READY_EVENT: threading.Event(),
        }

        # åˆ›å»ºæ˜¾ç¤ºç•Œé¢
        self.display = None
        set_xiaozhi(self)

    def run(self):
        self.protocol = WebsocketProtocol()

        # åˆ›å»ºå¹¶å¯åŠ¨äº‹ä»¶å¾ªç¯çº¿ç¨‹
        self.loop_thread = threading.Thread(target=self._run_event_loop)
        self.loop_thread.daemon = True
        self.loop_thread.start()

        # ç­‰å¾…äº‹ä»¶å¾ªç¯å‡†å¤‡å°±ç»ª
        time.sleep(0.1)

        # åˆå§‹åŒ–åº”ç”¨ç¨‹åº
        asyncio.run_coroutine_threadsafe(XiaoAI.init_xiaoai(), self.loop)
        asyncio.run_coroutine_threadsafe(self._initialize_xiaozhi(), self.loop)

        # å¯åŠ¨ä¸»å¾ªç¯çº¿ç¨‹
        main_loop_thread = threading.Thread(target=self._main_loop)
        main_loop_thread.daemon = True
        main_loop_thread.start()

        VAD.start()
        KWS.start()

        # å¯åŠ¨ GUI
        self._initialize_display()
        self.display.start()

    def _run_event_loop(self):
        """è¿è¡Œäº‹ä»¶å¾ªç¯çš„çº¿ç¨‹å‡½æ•°"""
        asyncio.set_event_loop(self.loop)
        self.loop.run_forever()

    async def _initialize_xiaozhi(self):
        """åˆå§‹åŒ–åº”ç”¨ç¨‹åºç»„ä»¶"""

        # åˆå§‹åŒ–éŸ³é¢‘ç¼–è§£ç å™¨
        self._initialize_audio()

        # è®¾ç½®åè®®å›è°ƒ
        self.protocol.on_network_error = self._on_network_error
        self.protocol.on_incoming_audio = self._on_incoming_audio
        self.protocol.on_incoming_json = self._on_incoming_json
        self.protocol.on_audio_channel_opened = self._on_audio_channel_opened
        self.protocol.on_audio_channel_closed = self._on_audio_channel_closed

        # æ‰“å¼€éŸ³é¢‘é€šé“
        self.device_state = DeviceState.CONNECTING
        await self.protocol.open_audio_channel()

    def _initialize_audio(self):
        """åˆå§‹åŒ–éŸ³é¢‘è®¾å¤‡å’Œç¼–è§£ç å™¨"""
        try:
            from xiaozhi.services.audio.codec import AudioCodec

            self.audio_codec = AudioCodec()
        except Exception as e:
            self.alert("é”™è¯¯", f"åˆå§‹åŒ–éŸ³é¢‘è®¾å¤‡å¤±è´¥: {e}")

    def _initialize_display(self):
        """åˆå§‹åŒ–æ˜¾ç¤ºç•Œé¢"""
        if get_env("CLI"):
            from xiaozhi.services.display import no_display

            self.display = no_display.NoDisplay()
        else:
            from xiaozhi.services.display import gui_display

            self.display = gui_display.GuiDisplay()

        # è®¾ç½®å›è°ƒå‡½æ•°
        self.display.set_callbacks(
            press_callback=self.start_listening,
            release_callback=self.stop_listening,
            status_callback=self._get_status_text,
            text_callback=self._get_current_text,
            emotion_callback=self._get_current_emotion,
            mode_callback=self._on_mode_changed,
            auto_callback=self.toggle_chat_state,
            abort_callback=lambda: self.abort_speaking(AbortReason.WAKE_WORD_DETECTED),
        )

    def _main_loop(self):
        """åº”ç”¨ç¨‹åºä¸»å¾ªç¯"""
        self.running = True

        while self.running:
            # ç­‰å¾…äº‹ä»¶
            for event_type, event in self.events.items():
                if event.is_set():
                    event.clear()

                    if event_type == EventType.AUDIO_INPUT_READY_EVENT:
                        self._handle_input_audio()
                    elif event_type == EventType.SCHEDULE_EVENT:
                        self._process_scheduled_tasks()

            time.sleep(0.01)

    def _process_scheduled_tasks(self):
        """å¤„ç†è°ƒåº¦ä»»åŠ¡"""
        with self.mutex:
            tasks = self.main_tasks.copy()
            self.main_tasks.clear()

        for task in tasks:
            try:
                task()
            except Exception:
                pass

    def schedule(self, callback):
        """è°ƒåº¦ä»»åŠ¡åˆ°ä¸»å¾ªç¯"""
        with self.mutex:
            # å¦‚æœæ˜¯ä¸­æ­¢è¯­éŸ³çš„ä»»åŠ¡ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒç±»å‹çš„ä»»åŠ¡
            if "abort_speaking" in str(callback):
                # å¦‚æœå·²ç»æœ‰ä¸­æ­¢ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼Œå°±ä¸å†æ·»åŠ 
                if any("abort_speaking" in str(task) for task in self.main_tasks):
                    return
            self.main_tasks.append(callback)
        self.events[EventType.SCHEDULE_EVENT].set()

    def _handle_input_audio(self):
        """å¤„ç†éŸ³é¢‘è¾“å…¥"""
        if self.device_state != DeviceState.LISTENING:
            return

        encoded_data = self.audio_codec.read_audio()
        if encoded_data and self.protocol and self.protocol.is_audio_channel_opened():
            asyncio.run_coroutine_threadsafe(
                self.protocol.send_audio(encoded_data), self.loop
            )

    def _on_network_error(self, message):
        """ç½‘ç»œé”™è¯¯å›è°ƒ"""
        self.set_device_state(DeviceState.IDLE)
        if self.device_state != DeviceState.CONNECTING:
            self.set_device_state(DeviceState.IDLE)

            # å…³é—­ç°æœ‰è¿æ¥
            if self.protocol:
                asyncio.run_coroutine_threadsafe(
                    self.protocol.close_audio_channel(), self.loop
                )

    def _on_incoming_audio(self, data):
        """æ¥æ”¶éŸ³é¢‘æ•°æ®å›è°ƒ"""
        if self.device_state == DeviceState.SPEAKING:
            self.audio_codec.write_audio(data)

    def _on_incoming_json(self, json_data):
        """æ¥æ”¶JSONæ•°æ®å›è°ƒ"""
        try:
            if not json_data:
                return

            # è§£æJSONæ•°æ®
            if isinstance(json_data, str):
                data = json.loads(json_data)
            else:
                data = json_data

            # å¤„ç†ä¸åŒç±»å‹çš„æ¶ˆæ¯
            msg_type = data.get("type", "")
            if msg_type == "tts":
                self._handle_tts_message(data)
            elif msg_type == "stt":
                self._handle_stt_message(data)
            elif msg_type == "llm":
                self._handle_llm_message(data)
        except Exception:
            pass

    def _handle_tts_message(self, data):
        """å¤„ç†TTSæ¶ˆæ¯"""
        state = data.get("state", "")
        if state == "start":
            EventManager.on_tts_start(data.get("session_id"))
            self.schedule(lambda: self._handle_tts_start())
        elif state == "stop":
            EventManager.on_tts_end(data.get("session_id"))
            self.schedule(lambda: self._handle_tts_stop())
        elif state == "sentence_start":
            text = data.get("text", "")
            if text:
                print(f"ğŸ¤– å°æ™ºï¼š{text}")

                verification_code = re.search(r"éªŒè¯ç .*?(\d+)", text) or re.search(
                    r"æ§åˆ¶é¢æ¿.*?(\d+)", text
                )
                if verification_code:
                    self.config.update_config_file(
                        "VERIFICATION_CODE", verification_code.group(1)
                    )

                self.schedule(lambda: self.set_chat_message("assistant", text))

    def _handle_tts_start(self):
        """å¤„ç†TTSå¼€å§‹äº‹ä»¶"""
        if (
            self.device_state == DeviceState.IDLE
            or self.device_state == DeviceState.LISTENING
        ):
            self.set_device_state(DeviceState.SPEAKING)

    def _handle_tts_stop(self):
        """å¤„ç†TTSåœæ­¢äº‹ä»¶"""
        pass

    def _handle_stt_message(self, data):
        """å¤„ç†STTæ¶ˆæ¯"""
        text = data.get("text", "")
        if text:
            print(f"ğŸ’¬ æˆ‘è¯´ï¼š{text}")
            self.schedule(lambda: self.set_chat_message("user", text))

    def _handle_llm_message(self, data):
        """å¤„ç†LLMæ¶ˆæ¯"""
        emotion = data.get("emotion", "")
        if emotion:
            self.schedule(lambda: self.set_emotion(emotion))

    async def _on_audio_channel_opened(self):
        """éŸ³é¢‘é€šé“æ‰“å¼€å›è°ƒ"""
        self.set_device_state(DeviceState.IDLE)
        threading.Thread(target=self._audio_input_event_trigger, daemon=True).start()

    def _audio_input_event_trigger(self):
        """éŸ³é¢‘è¾“å…¥äº‹ä»¶è§¦å‘å™¨"""
        while self.running:
            try:
                if self.audio_codec.input_stream.is_active():
                    self.events[EventType.AUDIO_INPUT_READY_EVENT].set()
            except OSError as e:
                if "Stream not open" in str(e):
                    break
            except Exception:
                pass

            time.sleep(0.01)

    async def _on_audio_channel_closed(self):
        """éŸ³é¢‘é€šé“å…³é—­å›è°ƒ"""
        self.set_device_state(DeviceState.IDLE)
        self.audio_codec.stop_streams()

    def set_device_state(self, state):
        """è®¾ç½®è®¾å¤‡çŠ¶æ€"""
        self.device_state = state

        VAD.pause()  # åœç”¨ VAD
        self.audio_codec.stop_streams()  # åœç”¨è¾“å…¥è¾“å‡ºæµ

        if state == DeviceState.IDLE:
            self.display.update_status("å¾…å‘½")
            self.display.update_emotion("ğŸ˜¶")
        elif state == DeviceState.CONNECTING:
            self.display.update_status("è¿æ¥ä¸­...")
        elif state == DeviceState.LISTENING:
            self.display.update_status("è†å¬ä¸­...")
            self.display.update_emotion("ğŸ™‚")
            # åœæ­¢è¾“å‡ºæµ
            if self.audio_codec.output_stream.is_active():
                self.audio_codec.output_stream.stop_stream()
            # æ‰“å¼€è¾“å…¥æµ
            if not self.audio_codec.input_stream.is_active():
                self.audio_codec.input_stream.start_stream()
        elif state == DeviceState.SPEAKING:
            self.display.update_status("è¯´è¯ä¸­...")
            # åœæ­¢è¾“å…¥æµ
            if self.audio_codec.input_stream.is_active():
                self.audio_codec.input_stream.stop_stream()
            # æ‰“å¼€è¾“å‡ºæµ
            if not self.audio_codec.output_stream.is_active():
                self.audio_codec.output_stream.start_stream()

        # é€šçŸ¥çŠ¶æ€å˜åŒ–
        for callback in self.on_state_changed_callbacks:
            try:
                callback(state)
            except Exception:
                pass

    def _get_status_text(self):
        """è·å–å½“å‰çŠ¶æ€æ–‡æœ¬"""
        states = {
            DeviceState.IDLE: "å¾…å‘½",
            DeviceState.CONNECTING: "è¿æ¥ä¸­...",
            DeviceState.LISTENING: "è†å¬ä¸­...",
            DeviceState.SPEAKING: "è¯´è¯ä¸­...",
        }
        return states.get(self.device_state, "æœªçŸ¥")

    def _get_current_text(self):
        """è·å–å½“å‰æ˜¾ç¤ºæ–‡æœ¬"""
        return self.current_text

    def _get_current_emotion(self):
        """è·å–å½“å‰è¡¨æƒ…"""
        emotions = {
            "neutral": "ğŸ˜¶",
            "happy": "ğŸ™‚",
            "laughing": "ğŸ˜†",
            "funny": "ğŸ˜‚",
            "sad": "ğŸ˜”",
            "angry": "ğŸ˜ ",
            "crying": "ğŸ˜­",
            "loving": "ğŸ˜",
            "embarrassed": "ğŸ˜³",
            "surprised": "ğŸ˜²",
            "shocked": "ğŸ˜±",
            "thinking": "ğŸ¤”",
            "winking": "ğŸ˜‰",
            "cool": "ğŸ˜",
            "relaxed": "ğŸ˜Œ",
            "delicious": "ğŸ¤¤",
            "kissy": "ğŸ˜˜",
            "confident": "ğŸ˜",
            "sleepy": "ğŸ˜´",
            "silly": "ğŸ˜œ",
            "confused": "ğŸ™„",
        }
        return emotions.get(self.current_emotion, "ğŸ˜¶")

    def set_chat_message(self, role, message):
        """è®¾ç½®èŠå¤©æ¶ˆæ¯"""
        self.current_text = message
        # æ›´æ–°æ˜¾ç¤º
        if self.display:
            self.display.update_text(message)

    def set_emotion(self, emotion):
        """è®¾ç½®è¡¨æƒ…"""
        self.current_emotion = emotion
        # æ›´æ–°æ˜¾ç¤º
        if self.display:
            self.display.update_emotion(self._get_current_emotion())

    def start_listening(self):
        """å¼€å§‹ç›‘å¬"""
        self.schedule(self._start_listening_impl)

    def _start_listening_impl(self):
        """å¼€å§‹ç›‘å¬çš„å®ç°"""
        if not self.protocol:
            return

        self.set_device_state(DeviceState.IDLE)
        asyncio.run_coroutine_threadsafe(
            self.protocol.send_abort_speaking(AbortReason.ABORT),
            self.loop,
        )
        asyncio.run_coroutine_threadsafe(
            self.protocol.send_start_listening(ListeningMode.MANUAL), self.loop
        )
        self.set_device_state(DeviceState.LISTENING)

    def stop_listening(self):
        """åœæ­¢ç›‘å¬"""
        self.schedule(self._stop_listening_impl)

    def _stop_listening_impl(self):
        """åœæ­¢ç›‘å¬çš„å®ç°"""
        asyncio.run_coroutine_threadsafe(self.protocol.send_stop_listening(), self.loop)
        self.set_device_state(DeviceState.IDLE)

    def abort_speaking(self, reason):
        """ä¸­æ­¢è¯­éŸ³è¾“å‡º"""
        self.set_device_state(DeviceState.IDLE)
        asyncio.run_coroutine_threadsafe(
            self.protocol.send_abort_speaking(AbortReason.ABORT),
            self.loop,
        )

    def alert(self, title, message):
        """æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯"""
        if self.display:
            self.display.update_text(f"{title}: {message}")

    def on_state_changed(self, callback):
        """æ³¨å†ŒçŠ¶æ€å˜åŒ–å›è°ƒ"""
        self.on_state_changed_callbacks.append(callback)

    def shutdown(self):
        """å…³é—­åº”ç”¨ç¨‹åº"""
        self.running = False

        # å…³é—­éŸ³é¢‘ç¼–è§£ç å™¨
        if self.audio_codec:
            self.audio_codec.close()

        # å…³é—­åè®®
        if self.protocol:
            asyncio.run_coroutine_threadsafe(
                self.protocol.close_audio_channel(), self.loop
            )

        # åœæ­¢äº‹ä»¶å¾ªç¯
        if self.loop and self.loop.is_running():
            self.loop.call_soon_threadsafe(self.loop.stop)

        # ç­‰å¾…äº‹ä»¶å¾ªç¯çº¿ç¨‹ç»“æŸ
        if self.loop_thread and self.loop_thread.is_alive():
            self.loop_thread.join(timeout=1.0)

    def toggle_chat_state(self):
        """åˆ‡æ¢èŠå¤©çŠ¶æ€"""
        pass

    def _on_mode_changed(self, auto_mode):
        """å¤„ç†å¯¹è¯æ¨¡å¼å˜æ›´"""
        pass
